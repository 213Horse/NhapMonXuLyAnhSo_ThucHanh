{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abb902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio.v2 as iio\n",
    "from PIL import Image\n",
    "import scipy.ndimage as sn\n",
    "from skimage import filters\n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "img = iio.imread('a.jpg')\n",
    "img_np = np.array(img)\n",
    "\n",
    "mean_filtered = sn.uniform_filter(img_np, size=(5, 5, 1))\n",
    "iio.imwrite('a_mean.jpg', mean_filtered.astype(np.uint8))\n",
    "\n",
    "gray = np.mean(img_np, axis=2).astype(np.uint8)\n",
    "edges = filters.sobel(gray) \n",
    "edges = (edges * 255).astype(np.uint8)\n",
    "iio.imwrite('a_edge.jpg', edges)\n",
    "\n",
    "perm = np.random.permutation(3)\n",
    "shuffled_img = img_np[:, :, perm]\n",
    "iio.imwrite('a_random_color.jpg', shuffled_img)\n",
    "\n",
    "def rgb_to_hsv_image(img):\n",
    "    img = img / 255.0\n",
    "    hsv = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            hsv[i, j] = colorsys.rgb_to_hsv(*img[i, j])\n",
    "    return hsv\n",
    "\n",
    "hsv_img = rgb_to_hsv_image(img_np.astype(float))\n",
    "h = (hsv_img[:, :, 0] * 255).astype(np.uint8)\n",
    "s = (hsv_img[:, :, 1] * 255).astype(np.uint8)\n",
    "v = (hsv_img[:, :, 2] * 255).astype(np.uint8)\n",
    "\n",
    "iio.imwrite('a_hue.jpg', h)\n",
    "iio.imwrite('a_saturation.jpg', s)\n",
    "iio.imwrite('a_value.jpg', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2955c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MENU BI·∫æN ƒê·ªîI ·∫¢NH ===\n",
      "Nh·∫•n ph√≠m I: Image inverse transformation\n",
      "Nh·∫•n ph√≠m G: Gamma Correction\n",
      "Nh·∫•n ph√≠m L: Log Transformation\n",
      "Nh·∫•n ph√≠m H: Histogram Equalization\n",
      "Nh·∫•n ph√≠m C: Contrast Stretching\n",
      "Nh·∫•n ph√≠m A: Adaptive Histogram Equalization\n",
      "ƒê√£ l∆∞u ·∫£nh: output_gamma_1.jpg\n",
      "ƒê√£ l∆∞u ·∫£nh: output_gamma_2.jpg\n",
      "ƒê√£ l∆∞u ·∫£nh: output_gamma_3.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "image_files = ['image1.jpg', 'image2.jpg', 'image3.jpg']\n",
    "\n",
    "# H√†m ƒë·ªçc t·∫•t c·∫£ ·∫£nh\n",
    "def read_images():\n",
    "    images = []\n",
    "    for f in image_files:\n",
    "        img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)  # D√πng ·∫£nh grayscale cho x·ª≠ l√Ω histogram\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc file {f}\")\n",
    "    return images\n",
    "\n",
    "# 1. Image Inverse (ƒë·∫£o ·∫£nh)\n",
    "def inverse_image(img):\n",
    "    return 255 - img\n",
    "\n",
    "# 2. Gamma Correction\n",
    "def gamma_correction(img, gamma=None):\n",
    "    if gamma is None:\n",
    "        gamma = random.uniform(0.5, 2.0)\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(img, table)\n",
    "\n",
    "# 3. Log Transformation\n",
    "def log_transformation(img, c=None):\n",
    "    if c is None:\n",
    "        c = random.uniform(1.0, 5.0)\n",
    "    img_float = img.astype(np.float32)\n",
    "    log_img = c * np.log1p(img_float)\n",
    "    log_img = np.clip((log_img / log_img.max()) * 255, 0, 255).astype(np.uint8)\n",
    "    return log_img\n",
    "\n",
    "# 4. Histogram Equalization\n",
    "def histogram_equalization(img):\n",
    "    return cv2.equalizeHist(img)\n",
    "\n",
    "# 5. Contrast Stretching\n",
    "def contrast_stretch(img):\n",
    "    min_val = random.randint(0, 50)\n",
    "    max_val = random.randint(200, 255)\n",
    "    stretched = np.clip((img - min_val) * 255.0 / (max_val - min_val), 0, 255)\n",
    "    return stretched.astype(np.uint8)\n",
    "\n",
    "# 6. Adaptive Histogram Equalization (CLAHE)\n",
    "def adaptive_hist_eq(img):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img)\n",
    "\n",
    "# Map ph√≠m sang h√†m x·ª≠ l√Ω\n",
    "transformations = {\n",
    "    'I': ('inverse', inverse_image),\n",
    "    'G': ('gamma', gamma_correction),\n",
    "    'L': ('log', log_transformation),\n",
    "    'H': ('histogram', histogram_equalization),\n",
    "    'C': ('contrast', contrast_stretch),\n",
    "    'A': ('adaptive', adaptive_hist_eq)\n",
    "}\n",
    "\n",
    "# Hi·ªÉn th·ªã menu l·ª±a ch·ªçn\n",
    "print(\"=== MENU BI·∫æN ƒê·ªîI ·∫¢NH ===\")\n",
    "print(\"Nh·∫•n ph√≠m I: Image inverse transformation\")\n",
    "print(\"Nh·∫•n ph√≠m G: Gamma Correction\")\n",
    "print(\"Nh·∫•n ph√≠m L: Log Transformation\")\n",
    "print(\"Nh·∫•n ph√≠m H: Histogram Equalization\")\n",
    "print(\"Nh·∫•n ph√≠m C: Contrast Stretching\")\n",
    "print(\"Nh·∫•n ph√≠m A: Adaptive Histogram Equalization\")\n",
    "choice = input(\"Vui l√≤ng nh·∫≠p ph√≠m t∆∞∆°ng ·ª©ng: \").upper()\n",
    "\n",
    "# Ki·ªÉm tra ph√≠m nh·∫≠p\n",
    "if choice in transformations:\n",
    "    method_name, func = transformations[choice]\n",
    "    images = read_images()\n",
    "\n",
    "    for idx, img in enumerate(images, start=1):\n",
    "        result = func(img)  # √Åp d·ª•ng bi·∫øn ƒë·ªïi ·∫£nh\n",
    "        filename = f\"output_{method_name}_{idx}.jpg\"\n",
    "        cv2.imwrite(filename, result)\n",
    "        print(f\"ƒê√£ l∆∞u ·∫£nh: {filename}\")\n",
    "else:\n",
    "    print(\"Ph√≠m kh√¥ng h·ª£p l·ªá.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777bf0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ x·ª≠ l√Ω ·∫£nh tr√°i c√¢y (resize + padding).\n",
      "‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file: quang-ninh.jpg. H√£y ki·ªÉm tra l·∫°i t√™n ho·∫∑c ƒë∆∞·ªùng d·∫´n.\n",
      "‚úÖ ƒê√£ x·ª≠ l√Ω ·∫£nh Pagoda (resize + blur).\n",
      "üîß √Åp d·ª•ng alpha = 1.46, beta = 46\n",
      "‚úÖ ƒê√£ √°p d·ª•ng contrast/brightness l√™n ·∫£nh Pagoda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1003.384] global loadsave.cpp:248 findDecoder imread_('quang-ninh.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def read_image_safely(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    if img is None:\n",
    "        print(f\"Kh√¥ng th·ªÉ ƒë·ªçc file: {filename}. H√£y ki·ªÉm tra l·∫°i t√™n ho·∫∑c ƒë∆∞·ªùng d·∫´n.\")\n",
    "    return img\n",
    "\n",
    "img_fruits = read_image_safely('colorful-ripe-tropical-fruits.jpg')\n",
    "if img_fruits is not None:\n",
    "    img_fruits_resized = cv2.copyMakeBorder(img_fruits, 30, 30, 30, 30, borderType=cv2.BORDER_REPLICATE)\n",
    "    cv2.imwrite('output_fruits_resized.jpg', img_fruits_resized)\n",
    "    print(\"ƒê√£ x·ª≠ l√Ω ·∫£nh tr√°i c√¢y (resize + padding).\")\n",
    "\n",
    "def rotate_and_flip(img, angle):\n",
    "    (h, w) = img.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (w, h))\n",
    "    flipped = cv2.flip(rotated, 1)\n",
    "    return flipped\n",
    "\n",
    "img_quangninh = read_image_safely('quang-ninh.jpg')\n",
    "if img_quangninh is not None:\n",
    "    img_quangninh_transformed = rotate_and_flip(img_quangninh, 45)\n",
    "    cv2.imwrite('output_quangninh_rotated_flipped.jpg', img_quangninh_transformed)\n",
    "    print(\"ƒê√£ x·ª≠ l√Ω ·∫£nh Qu·∫£ng Ninh (xoay + l·∫≠t).\")\n",
    "\n",
    "def upscale_and_blur(img, scale=5, kernel_size=(7,7)):\n",
    "    upscaled = cv2.resize(img, (0,0), fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "    blurred = cv2.GaussianBlur(upscaled, kernel_size, 0)\n",
    "    return blurred\n",
    "\n",
    "img_pagoda = read_image_safely('pagoda.jpg')\n",
    "if img_pagoda is not None:\n",
    "    img_pagoda_blurred = upscale_and_blur(img_pagoda)\n",
    "    cv2.imwrite('output_pagoda_upscaled_blur.jpg', img_pagoda_blurred)\n",
    "    print(\"ƒê√£ x·ª≠ l√Ω ·∫£nh Pagoda (resize + blur).\")\n",
    "\n",
    "    def adjust_brightness_contrast(img, alpha=None, beta=None):\n",
    "        if alpha is None:\n",
    "            alpha = random.uniform(0.5, 2.0)\n",
    "        if beta is None:\n",
    "            beta = random.randint(-50, 50)\n",
    "        print(f\"√Åp d·ª•ng alpha = {alpha:.2f}, beta = {beta}\")\n",
    "        adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "        return adjusted\n",
    "\n",
    "    img_pagoda_adjusted = adjust_brightness_contrast(img_pagoda)\n",
    "    cv2.imwrite('output_pagoda_contrast_brightness.jpg', img_pagoda_adjusted)\n",
    "    print(\"ƒê√£ √°p d·ª•ng contrast/brightness l√™n ·∫£nh Pagoda.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
